# LLM API Keys
OPENAI_API_KEY="your-openai-api-key-here"
ANTHROPIC_API_KEY="your-anthropic-api-key-here"
DEEPSEEK_API_KEY="your-deepseek-api-key-here"
GEMINI_API_KEY="your-gemini-api-key-here"

# Primary LLM Provider for mindmap generation
# Options: "OPENAI", "CLAUDE", "DEEPSEEK", "GEMINI", or "OLLAMA"
API_PROVIDER="OLLAMA"

# LightRAG Configuration (following your lightrag_ex.py and lightrag_manager.py)
LLM_MODEL="qwen3-coder:30b"  
EMBEDDING_MODEL="bge-m3:latest"
LLM_HOST="http://100.95.157.120:11434"  # Your specific host from lightrag_manager.py
EMBEDDING_HOST="http://100.95.157.120:11434"
EMBEDDING_DIM="1024"  # Your setting (not 1536) - this must match your embedding model
MAX_EMBED_TOKENS="8192"  # lightrag_ex.py uses "40000" but lightrag_manager.py uses "8192"
TIMEOUT="3000"  # 3000 seconds from your files (not 300)
EMBEDDING_TIMEOUT="6000"  # 6000 seconds from your files (not 600)

# Storage Configuration (following your lightrag_ex.py structure)
WORKING_DIR="./bookworm_workspace"  # Your exact path from lightrag_ex.py
DOCUMENT_DIR="./bookworm_workspace/docs"
PROCESSED_DIR="./bookworm_workspace/processed_docs"  # Following your DOCUMENT_ARCHIVE_DIR pattern
OUTPUT_DIR="./bookworm_workspace/output"

# PDF Processing
PDF_PROCESSOR="mineru"  # Options: "mineru", "docling", "pymupdf", "pdfplumber"
SKIP_PDF_CONVERSION="false"

# Logging
LOG_LEVEL="INFO"
LOG_DIR="./logs"
LOG_MAX_BYTES="10485760"  # 10MB
LOG_BACKUP_COUNT="5"

# Performance Settings
MAX_CONCURRENT_PROCESSES="4"
CHUNK_SIZE="8192"
MAX_FILE_SIZE_MB="100"
